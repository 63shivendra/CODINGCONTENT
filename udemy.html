<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Machine Learning Topics: Detailed Explanations, Formulas, Diagrams, Charts & Interview Questions</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; background-color: #f4f4f4; color: #333; }
        h1 { text-align: center; color: #2c3e50; }
        section { margin: 20px 0; padding: 20px; background: white; border-radius: 8px; box-shadow: 0 2px 5px rgba(0,0,0,0.1); }
        h2 { color: #34495e; border-bottom: 2px solid #3498db; padding-bottom: 10px; }
        h3 { color: #2980b9; }
        ul { list-style-type: disc; padding-left: 20px; }
        svg { border: 1px solid #ddd; display: block; margin: 10px 0; }
        canvas { max-width: 400px; margin: 10px 0; }
        .formula { background: #ecf0f1; padding: 10px; border-left: 4px solid #3498db; margin: 10px 0; }
        .interview { background: #e8f6f3; padding: 10px; border-radius: 4px; margin: 10px 0; }
    </style>
</head>
<body>
    <h1>Machine Learning Topics from Udemy Course: Explanations, Usage, Formulas, Visuals & Interview Qs</h1>
    
    <section id="preprocessing">
        <h2>1. Data Preprocessing (Python & R)</h2>
        <p><strong>Explanation:</strong> Data preprocessing involves cleaning, transforming, and preparing raw data for ML models. Steps include handling missing values, scaling features, encoding categoricals, and splitting data. Essential to avoid biases and improve model performance.</p>
        <h3>When/Where to Use:</h3>
        <p>Use before training any ML model; in data science pipelines for tabular data in Python (Pandas, Scikit-learn) or R (dplyr, caret).</p>
        <h3>Mathematical Formulas:</h3>
        <div class="formula">
            <p>Min-Max Scaling: \( x' = \frac{x - \min(X)}{\max(X) - \min(X)} \)</p>
            <p>Z-Score Normalization: \( x' = \frac{x - \mu}{\sigma} \)</p>
            <p>One-Hot Encoding: Binary vectors for categories.</p>
        </div>
        <h3>Diagram:</h3>
        <svg width="300" height="150">
            <rect x="10" y="10" width="280" height="130" fill="none" stroke="#3498db"/>
            <text x="50" y="40">Raw Data</text>
            <line x1="150" y1="30" x2="150" y2="120" stroke="#e74c3c" stroke-width="2"/>
            <text x="170" y="40">Clean → Scale → Encode</text>
            <text x="50" y="120">Processed Data</text>
            <circle cx="150" cy="75" r="20" fill="#2ecc71"/>
        </svg>
        <h3>Chart: Feature Scaling Impact</h3>
        <canvas id="chart-preprocess"></canvas>
        <script>
            const ctx1 = document.getElementById('chart-preprocess').getContext('2d');
            new Chart(ctx1, {
                type: 'bar',
                data: { labels: ['Before', 'After'], datasets: [{ label: 'Accuracy', data: [0.7, 0.92], backgroundColor: ['#e74c3c', '#2ecc71'] }] },
                options: { scales: { y: { beginAtZero: true } } }
            });
        </script>
        <h3>Important Interview Questions:</h3>
        <div class="interview">
            <ul>
                <li>Q: How do you handle missing values in a dataset? (Ans: Imputation via mean/median, or removal if <5%.)</li>
                <li>Q: Difference between normalization and standardization? (Ans: Normalization to [0,1]; standardization to mean=0, sd=1.)</li>
                <li>Q: Why encode categorical variables? (Ans: Models require numerical input; one-hot for nominal, label for ordinal.)</li>
                <li>Q: Train-test split ratio? (Ans: Typically 80/20.)</li>
                <li>Q: Overfitting due to preprocessing? (Ans: Yes, if leakage from test to train.)</li>
            </ul>
        </div>
    </section>

    <section id="slr">
        <h2>2. Simple Linear Regression</h2>
        <p><strong>Explanation:</strong> Models relationship between one independent (x) and one dependent variable (y) as a straight line. Used for prediction and correlation analysis.</p>
        <h3>When/Where to Use:</h3>
        <p>When linear relationship assumed; e.g., predicting house price from size in real estate apps.</p>
        <h3>Mathematical Formulas:</h3>
        <div class="formula">
            <p>Line Equation: \( y = \beta_0 + \beta_1 x + \epsilon \)</p>
            <p>Least Squares: \( \beta_1 = \frac{\sum (x_i - \bar{x})(y_i - \bar{y})}{\sum (x_i - \bar{x})^2} \), \( \beta_0 = \bar{y} - \beta_1 \bar{x} \)</p>
            <p>MSE: \( \frac{1}{n} \sum (y_i - \hat{y_i})^2 \)</p>
        </div>
        <h3>Diagram:</h3>
        <svg width="300" height="200">
            <line x1="50" y1="150" x2="250" y2="50" stroke="#3498db" stroke-width="2"/>
            <circle cx="100" cy="120" r="3" fill="#e74c3c"/>
            <circle cx="150" cy="100" r="3" fill="#e74c3c"/>
            <circle cx="200" cy="70" r="3" fill="#e74c3c"/>
            <text x="100" y="180">Scatter Plot with Fit Line</text>
        </svg>
        <h3>Chart: Predictions vs Actual</h3>
        <canvas id="chart-slr"></canvas>
        <script>
            const ctx2 = document.getElementById('chart-slr').getContext('2d');
            new Chart(ctx2, {
                type: 'scatter',
                data: { datasets: [{ label: 'Data', data: [{x:1,y:2},{x:2,y:3.5},{x:3,y:5}], backgroundColor: '#e74c3c' }] },
                options: { scales: { x: { type: 'linear' } } }
            });
        </script>
        <h3>Important Interview Questions:</h3>
        <div class="interview">
            <ul>
                <li>Q: What are assumptions of SLR? (Ans: Linearity, independence, homoscedasticity, normality.)</li>
                <li>Q: How to interpret coefficients? (Ans: β1 is change in y per unit x.)</li>
                <li>Q: R-squared meaning? (Ans: Proportion of variance explained.)</li>
                <li>Q: Underfitting in SLR? (Ans: High bias, poor fit to data.)</li>
                <li>Q: Gradient descent for fitting? (Ans: Minimize MSE via ∂L/∂β.)</li>
            </ul>
        </div>
    </section>

    <section id="mlr">
        <h2>3. Multiple Linear Regression</h2>
        <p><strong>Explanation:</strong> Extends SLR to multiple independent variables. Fits a hyperplane to data.</p>
        <h3>When/Where to Use:</h3>
        <p>Multiple predictors; e.g., salary prediction from experience, education, location in HR analytics.</p>
        <h3>Mathematical Formulas:</h3>
        <div class="formula">
            <p>Equation: \( y = \beta_0 + \beta_1 x_1 + \dots + \beta_p x_p + \epsilon \)</p>
            <p>Vector Form: \( \mathbf{y} = X \boldsymbol{\beta} + \boldsymbol{\epsilon} \), \( \boldsymbol{\beta} = (X^T X)^{-1} X^T \mathbf{y} \)</p>
        </div>
        <h3>Diagram:</h3>
        <svg width="300" height="150">
            <polygon points="50,100 150,50 250,120" fill="none" stroke="#3498db"/>
            <text x="120" y="80">Hyperplane in 3D</text>
        </svg>
        <h3>Chart: Coefficient Importance</h3>
        <canvas id="chart-mlr"></canvas>
        <script>
            const ctx3 = document.getElementById('chart-mlr').getContext('2d');
            new Chart(ctx3, { type: 'bar', data: { labels: ['X1', 'X2', 'X3'], datasets: [{ label: 'Beta', data: [2.5, 1.8, 0.9], backgroundColor: '#3498db' }] } });
        </script>
        <h3>Important Interview Questions:</h3>
        <div class="interview">
            <ul>
                <li>Q: Multicollinearity issue? (Ans: High correlation between features; detect via VIF >5.)</li>
                <li>Q: Adjusted R-squared? (Ans: Penalizes extra variables.)</li>
                <li>Q: Feature selection in MLR? (Ans: Forward/backward stepwise.)</li>
                <li>Q: Heteroscedasticity? (Ans: Violates constant variance; use Breusch-Pagan test.)</li>
                <li>Q: Ridge vs Lasso? (Ans: Ridge for multicollinearity, Lasso for selection.)</li>
            </ul>
        </div>
    </section>

    <section id="poly">
        <h2>4. Polynomial Regression</h2>
        <p><strong>Explanation:</strong> Fits non-linear relationships by raising features to powers, turning into multiple regression.</p>
        <h3>When/Where to Use:</h3>
        <p>Curved relationships; e.g., growth curves in biology or marketing response.</p>
        <h3>Mathematical Formulas:</h3>
        <div class="formula">
            <p>Equation: \( y = \beta_0 + \beta_1 x + \beta_2 x^2 + \dots + \beta_d x^d + \epsilon \)</p>
            <p>Degree d chosen via cross-validation to avoid overfitting.</p>
        </div>
        <h3>Diagram:</h3>
        <svg width="300" height="200">
            <path d="M50 150 Q150 50 250 150" stroke="#3498db" fill="none" stroke-width="2"/>
            <text x="120" y="180">Polynomial Curve</text>
        </svg>
        <h3>Chart: Fit Degrees</h3>
        <canvas id="chart-poly"></canvas>
        <script>
            const ctx4 = document.getElementById('chart-poly').getContext('2d');
            new Chart(ctx4, { type: 'line', data: { labels: [1,2,3,4,5], datasets: [{ label: 'Degree 2', data: [1,4,9,16,25], borderColor: '#e67e22' }] } });
        </script>
        <h3>Important Interview Questions:</h3>
        <div class="interview">
            <ul>
                <li>Q: How to choose polynomial degree? (Ans: CV, AIC/BIC.)</li>
                <li>Q: Overfitting risk? (Ans: High degree; use regularization.)</li>
                <li>Q: Interaction terms? (Ans: \( x_1 x_2 \) for non-linear interactions.)</li>
                <li>Q: Vs non-parametric? (Ans: Parametric, assumes form.)</li>
                <li>Q: Implementation in scikit-learn? (Ans: PolynomialFeatures transformer.)</li>
            </ul>
        </div>
    </section>

    <section id="svr">
        <h2>5. Support Vector Regression (SVR)</h2>
        <p><strong>Explanation:</strong> SVR uses support vector machines for regression, finding a hyperplane that fits within epsilon-tube of data.</p>
        <h3>When/Where to Use:</h3>
        <p>Non-linear regression with outliers; e.g., stock price prediction.</p>
        <h3>Mathematical Formulas:</h3>
        <div class="formula">
            <p>Objective: Minimize \( \frac{1}{2} ||w||^2 + C \sum (\xi_i + \xi_i^*) \)</p>
            <p>Subject to \( |y_i - (w \cdot \phi(x_i) + b)| \leq \epsilon + \xi_i \)</p>
        </div>
        <h3>Diagram:</h3>
        <svg width="300" height="200">
            <line x1="50" y1="100" x2="250" y2="100" stroke="#3498db" stroke-width="2"/>
            <line x1="50" y1="80" x2="250" y2="80" stroke="#e74c3c" stroke-width="1" stroke-dasharray="5"/>
            <line x1="50" y1="120" x2="250" y2="120" stroke="#e74c3c" stroke-width="1" stroke-dasharray="5"/>
            <text x="100" y="140">Epsilon Tube</text>
        </svg>
        <h3>Chart: SVR Fit</h3>
        <canvas id="chart-svr"></canvas>
        <script>
            const ctx5 = document.getElementById('chart-svr').getContext('2d');
            new Chart(ctx5, { type: 'line', data: { labels: [1,2,3,4], datasets: [{ label: 'SVR', data: [2,3,5,4], borderColor: '#9b59b6' }] } });
        </script>
        <h3>Important Interview Questions:</h3>
        <div class="interview">
            <ul>
                <li>Q: Difference SVR vs linear reg? (Ans: Insensitive to outliers via epsilon.)</li>
                <li>Q: Kernel trick in SVR? (Ans: RBF for non-linear.)</li>
                <li>Q: C and epsilon params? (Ans: C=tradeoff, epsilon=tube width.)</li>
                <li>Q: Support vectors role? (Ans: Define the boundary.)</li>
                <li>Q: Scale data for SVR? (Ans: Yes, kernel sensitive.)</li>
            </ul>
        </div>
    </section>

    <section id="dtr">
        <h2>6. Decision Tree Regression</h2>
        <p><strong>Explanation:</strong> Tree-based model that splits data recursively to minimize variance; leaf nodes predict mean.</p>
        <h3>When/Where to Use:</h3>
        <p>Non-linear, interpretable models; e.g., customer churn prediction.</p>
        <h3>Mathematical Formulas:</h3>
        <div class="formula">
            <p>Split Criterion: MSE = \( \frac{1}{n} \sum (y_i - \bar{y})^2 \)</p>
            <p>Gain = Parent MSE - Weighted Child MSE</p>
        </div>
        <h3>Diagram:</h3>
        <svg width="300" height="200">
            <line x1="150" y1="20" x2="150" y2="180" stroke="#2c3e50" stroke-width="2"/>
            <line x1="100" y1="100" x2="50" y2="150" stroke="#2c3e50"/>
            <line x1="200" y1="100" x2="250" y2="150" stroke="#2c3e50"/>
            <text x="140" y="10">Root</text>
            <text x="40" y="160">Leaf</text>
        </svg>
        <h3>Chart: Tree Depth vs Error</h3>
        <canvas id="chart-dtr"></canvas>
        <script>
            const ctx6 = document.getElementById('chart-dtr').getContext('2d');
            new Chart(ctx6, { type: 'line', data: { labels: [1,2,3,4,5], datasets: [{ label: 'MSE', data: [10,6,4,3,5], borderColor: '#27ae60' }] } });
        </script>
        <h3>Important Interview Questions:</h3>
        <div class="interview">
            <ul>
                <li>Q: Pruning in DT? (Ans: Reduce overfitting by removing branches.)</li>
                <li>Q: Gini vs Entropy? (Ans: Gini faster, Entropy info gain.)</li>
                <li>Q: Max depth param? (Ans: Controls complexity.)</li>
                <li>Q: Pros over linear? (Ans: Handles non-linearity, no assumptions.)</li>
                <li>Q: Instability? (Ans: Small data change = big tree change; use ensembles.)</li>
            </ul>
        </div>
    </section>

    <section id="rfr">
        <h2>7. Random Forest Regression</h2>
        <p><strong>Explanation:</strong> Ensemble of decision trees using bagging and random feature selection; averages predictions.</p>
        <h3>When/Where to Use:</h3>
        <p>High accuracy needed, handles overfitting; e.g., medical diagnosis.</p>
        <h3>Mathematical Formulas:</h3>
        <div class="formula">
            <p>Prediction: \( \hat{y} = \frac{1}{B} \sum_{b=1}^B T_b(x) \)</p>
            <p>OOB Error for validation.</p>
        </div>
        <h3>Diagram:</h3>
        <svg width="300" height="200">
            <rect x="50" y="20" width="40" height="40" fill="#3498db"/>
            <rect x="120" y="80" width="40" height="40" fill="#3498db"/>
            <rect x="200" y="140" width="40" height="40" fill="#3498db"/>
            <text x="140" y="10">Multiple Trees → Average</text>
        </svg>
        <h3>Chart: Feature Importance</h3>
        <canvas id="chart-rfr"></canvas>
        <script>
            const ctx7 = document.getElementById('chart-rfr').getContext('2d');
            new Chart(ctx7, { type: 'bar', data: { labels: ['Feat1', 'Feat2'], datasets: [{ label: 'Importance', data: [0.6, 0.4], backgroundColor: '#f39c12' }] } });
        </script>
        <h3>Important Interview Questions:</h3>
        <div class="interview">
            <ul>
                <li>Q: Bagging vs Boosting? (Ans: Bagging parallel, equal weight; Boosting sequential, weights errors.)</li>
                <li>Q: n_estimators? (Ans: Number of trees; more = better but slower.)</li>
                <li>Q: Random features? (Ans: sqrt(n_features) for classification.)</li>
                <li>Q: Variance reduction? (Ans: Averaging uncorrelated trees.)</li>
                <li>Q: Hyperparam tuning? (Ans: Max_features, min_samples_split.)</li>
            </ul>
        </div>
    </section>

    <section id="logr">
        <h2>8. Logistic Regression</h2>
        <p><strong>Explanation:</strong> For binary classification; uses sigmoid to map linear combo to [0,1] probability.</p>
        <h3>When/Where to Use:</h3>
        <p>Binary outcomes; e.g., spam detection, disease prediction.</p>
        <h3>Mathematical Formulas:</h3>
        <div class="formula">
            <p>Sigmoid: \( p = \frac{1}{1 + e^{-z}} \), z = β0 + β1x</p>
            <p>Log-Loss: \( - [y \log p + (1-y) \log (1-p)] \)</p>
        </div>
        <h3>Diagram:</h3>
        <svg width="300" height="200">
            <path d="M50 150 Q150 100 250 150" stroke="#e74c3c" fill="none"/>
            <text x="120" y="180">S-Curve</text>
        </svg>
        <h3>Chart: ROC Curve</h3>
        <canvas id="chart-logr"></canvas>
        <script>
            const ctx8 = document.getElementById('chart-logr').getContext('2d');
            new Chart(ctx8, { type: 'line', data: { labels: [0,0.5,1], datasets: [{ label: 'ROC', data: [0,0.7,1], borderColor: '#e74c3c' }] } });
        </script>
        <h3>Important Interview Questions:</h3>
        <div class="interview">
            <ul>
                <li>Q: Why sigmoid? (Ans: Bounds to [0,1] for prob.)</li>
                <li>Q: Multinomial extension? (Ans: Softmax for multi-class.)</li>
                <li>Q: Threshold 0.5? (Ans: Balances precision/recall; tune via ROC.)</li>
                <li>Q: Assumptions? (Ans: Linear in logit, no multicollinearity.)</li>
                <li>Q: L1/L2 reg? (Ans: Lasso/Ridge to prevent overfitting.)</li>
            </ul>
        </div>
    </section>

    <section id="knn">
        <h2>9. K-Nearest Neighbors (KNN)</h2>
        <p><strong>Explanation:</strong> Instance-based; classifies based on majority vote of k closest training points.</p>
        <h3>When/Where to Use:</h3>
        <p>Small datasets, non-parametric; e.g., recommendation systems.</p>
        <h3>Mathematical Formulas:</h3>
        <div class="formula">
            <p>Distance: Euclidean \( d = \sqrt{\sum (x_i - y_i)^2} \)</p>
            <p>Vote: Argmax class in k neighbors.</p>
        </div>
        <h3>Diagram:</h3>
        <svg width="300" height="200">
            <circle cx="150" cy="100" r="80" fill="none" stroke="#3498db"/>
            <circle cx="100" cy="80" r="5" fill="#2ecc71"/>
            <circle cx="200" cy="120" r="5" fill="#2ecc71"/>
            <text x="140" y="180">K=3 Neighbors</text>
        </svg>
        <h3>Chart: K vs Accuracy</h3>
        <canvas id="chart-knn"></canvas>
        <script>
            const ctx9 = document.getElementById('chart-knn').getContext('2d');
            new Chart(ctx9, { type: 'line', data: { labels: [1,3,5,7], datasets: [{ label: 'Acc', data: [0.8,0.85,0.9,0.88], borderColor: '#1abc9c' }] } });
        </script>
        <h3>Important Interview Questions:</h3>
        <div class="interview">
            <ul>
                <li>Q: Choose k? (Ans: Odd to avoid ties; CV for elbow.)</li>
                <li>Q: Lazy learner? (Ans: No training, stores data.)</li>
                <li>Q: Curse of dimensionality? (Ans: Distance meaningless in high dims.)</li>
                <li>Q: Weighted KNN? (Ans: Inverse distance weights.)</li>
                <li>Q: Scalability issue? (Ans: O(n) prediction; use KD-tree.)</li>
            </ul>
        </div>
    </section>

    <section id="svm">
        <h2>10. Support Vector Machine (SVM)</h2>
        <p><strong>Explanation:</strong> Finds hyperplane maximizing margin between classes; kernels for non-linear.</p>
        <h3>When/Where to Use:</h3>
        <p>High-dim data, clear margins; e.g., image classification.</p>
        <h3>Mathematical Formulas:</h3>
        <div class="formula">
            <p>Maximize \( \frac{2}{||w||} \) s.t. \( y_i (w \cdot x_i + b) \geq 1 \)</p>
            <p>Soft Margin: + C ∑ ξ_i</p>
        </div>
        <h3>Diagram:</h3>
        <svg width="300" height="200">
            <line x1="50" y1="100" x2="250" y2="100" stroke="#3498db" stroke-width="3"/>
            <line x1="50" y1="80" x2="250" y2="80" stroke="#e74c3c" stroke-width="1"/>
            <line x1="50" y1="120" x2="250" y2="120" stroke="#e74c3c" stroke-width="1"/>
            <text x="100" y="140">Margin</text>
        </svg>
        <h3>Chart: Kernel Comparison</h3>
        <canvas id="chart-svm"></canvas>
        <script>
            const ctx10 = document.getElementById('chart-svm').getContext('2d');
            new Chart(ctx10, { type: 'bar', data: { labels: ['Linear', 'RBF'], datasets: [{ label: 'Acc', data: [0.85, 0.92], backgroundColor: ['#34495e', '#9b59b6'] }] } });
        </script>
        <h3>Important Interview Questions:</h3>
        <div class="interview">
            <ul>
                <li>Q: Hard vs Soft margin? (Ans: Hard no errors; soft allows via C.)</li>
                <li>Q: Kernel types? (Ans: Linear, poly, RBF, sigmoid.)</li>
                <li>Q: Gamma param? (Ans: Influences decision curve; high=overfit.)</li>
                <li>Q: Dual problem? (Ans: For non-linear via Lagrange.)</li>
                <li>Q: SVM for regression? (Ans: SVR variant.)</li>
            </ul>
        </div>
    </section>

    <section id="nb">
        <h2>11. Naive Bayes</h2>
        <p><strong>Explanation:</strong> Probabilistic classifier assuming feature independence; uses Bayes' theorem.</p>
        <h3>When/Where to Use:</h3>
        <p>Text classification, fast; e.g., sentiment analysis.</p>
        <h3>Mathematical Formulas:</h3>
        <div class="formula">
            <p>\( P(c|x) = \frac{P(x|c) P(c)}{P(x)} \approx P(c) \prod P(x_i|c) \)</p>
            <p>Gaussian: \( P(x|c) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}} \)</p>
        </div>
        <h3>Diagram:</h3>
        <svg width="300" height="150">
            <circle cx="150" cy="75" r="50" fill="#3498db"/>
            <text x="130" y="80">P(c|x) Decision</text>
        </svg>
        <h3>Chart: Class Priors</h3>
        <canvas id="chart-nb"></canvas>
        <script>
            const ctx11 = document.getElementById('chart-nb').getContext('2d');
            new Chart(ctx11, { type: 'pie', data: { labels: ['Class A', 'Class B'], datasets: [{ data: [0.6, 0.4], backgroundColor: ['#e74c3c', '#2ecc71'] }] } });
        </script>
        <h3>Important Interview Questions:</h3>
        <div class="interview">
            <ul>
                <li>Q: "Naive" assumption? (Ans: Conditional independence; often holds approximately.)</li>
                <li>Q: Variants? (Ans: Gaussian, Multinomial, Bernoulli.)</li>
                <li>Q: Zero probability issue? (Ans: Laplace smoothing.)</li>
                <li>Q: When better than logistic? (Ans: Small data, high dims.)</li>
                <li>Q: Bayes theorem proof? (Ans: Posterior ∝ likelihood * prior.)</li>
            </ul>
        </div>
    </section>

    <section id="dtc">
        <h2>12. Decision Tree Classification</h2>
        <p><strong>Explanation:</strong> Similar to regression but splits to maximize purity (e.g., Gini); leaves assign majority class.</p>
        <h3>When/Where to Use:</h3>
        <p>Interpretable classification; e.g., credit risk.</p>
        <h3>Mathematical Formulas:</h3>
        <div class="formula">
            <p>Gini: \( 1 - \sum p_i^2 \)</p>
            <p>Info Gain: \( Entropy(parent) - \sum w Entropy(child) \)</p>
        </div>
        <h3>Diagram:</h3>
        <svg width="300" height="200">
            <line x1="150" y1="20" x2="150" y2="180" stroke="#2c3e50"/>
            <text x="140" y="10">Class Splits</text>
        </svg>
        <h3>Chart: Gini Scores</h3>
        <canvas id="chart-dtc"></canvas>
        <script>
            const ctx12 = document.getElementById('chart-dtc').getContext('2d');
            new Chart(ctx12, { type: 'bar', data: { labels: ['Node1', 'Node2'], datasets: [{ label: 'Gini', data: [0.4, 0.2], backgroundColor: '#27ae60' }] } });
        </script>
        <h3>Important Interview Questions:</h3>
        <div class="interview">
            <ul>
                <li>Q: Gini vs Entropy? (Ans: Gini quadratic, faster; Entropy log-based.)</li>
                <li>Q: Imbalanced classes? (Ans: Class weights or SMOTE.)</li>
                <li>Q: Visualization? (Ans: export_graphviz in sklearn.)</li>
                <li>Q: Bias-variance? (Ans: High variance; ensemble to fix.)</li>
                <li>Q: Cost complexity pruning? (Ans: α param for subtree size.)</li>
            </ul>
        </div>
    </section>

    <section id="rfc">
        <h2>13. Random Forest Classification</h2>
        <p><strong>Explanation:</strong> Ensemble for classification; majority vote across trees.</p>
        <h3>When/Where to Use:</h3>
        <p>Robust classification; e.g., fraud detection.</p>
        <h3>Mathematical Formulas:</h3>
        <div class="formula">
            <p>Class: \( \hat{y} = \mode \{ T_b(x) \}_{b=1}^B \)</p>
        </div>
        <h3>Diagram:</h3>
        <svg width="300" height="200">
            <rect x="50" y="20" width="40" height="40" fill="#3498db"/>
            <rect x="120" y="80" width="40" height="40" fill="#3498db"/>
            <text x="140" y="10">Vote Majority</text>
        </svg>
        <h3>Chart: OOB Accuracy</h3>
        <canvas id="chart-rfc"></canvas>
        <script>
            const ctx13 = document.getElementById('chart-rfc').getContext('2d');
            new Chart(ctx13, { type: 'line', data: { labels: [50,100,200], datasets: [{ label: 'OOB', data: [0.85,0.88,0.9], borderColor: '#f39c12' }] } });
        </script>
        <h3>Important Interview Questions:</h3>
        <div class="interview">
            <ul>
                <li>Q: How reduces variance? (Ans: Bootstrap + random features.)</li>
                <li>Q: Class imbalance? (Ans: Balanced class weights.)</li>
                <li>Q: Feature importance? (Ans: Mean decrease impurity.)</li>
                <li>Q: Vs XGBoost? (Ans: RF parallel; XGB sequential.)</li>
                <li>Q: Max_samples? (Ans: Bootstrap sample size.)</li>
            </ul>
        </div>
    </section>

    <section id="kmeans">
        <h2>14. K-Means Clustering</h2>
        <p><strong>Explanation:</strong> Partitions data into k clusters by minimizing within-cluster variance; iterative assignment/centroid update.</p>
        <h3>When/Where to Use:</h3>
        <p>Unsupervised grouping; e.g., customer segmentation.</p>
        <h3>Mathematical Formulas:</h3>
        <div class="formula">
            <p>Objective: \( \arg\min \sum_{i=1}^k \sum_{x \in C_i} ||x - \mu_i||^2 \)</p>
            <p>Elbow for k selection.</p>
        </div>
        <h3>Diagram:</h3>
        <svg width="300" height="200">
            <circle cx="100" cy="100" r="30" fill="#e74c3c"/>
            <circle cx="200" cy="100" r="30" fill="#3498db"/>
            <text x="120" y="180">Centroids</text>
        </svg>
        <h3>Chart: Elbow Method</h3>
        <canvas id="chart-kmeans"></canvas>
        <script>
            const ctx14 = document.getElementById('chart-kmeans').getContext('2d');
            new Chart(ctx14, { type: 'line', data: { labels: [1,2,3,4,5], datasets: [{ label: 'SSE', data: [100,50,30,25,20], borderColor: '#9b59b6' }] } });
        </script>
        <h3>Important Interview Questions:</h3>
        <div class="interview">
            <ul>
                <li>Q: Local optima issue? (Ans: Multiple random inits.)</li>
                <li>Q: K selection? (Ans: Elbow, silhouette score.)</li>
                <li>Q: Spherical assumption? (Ans: Yes; use GMM for non-spherical.)</li>
                <li>Q: Scalability? (Ans: O(nkt); mini-batch for large.)</li>
                <li>Q: Outliers effect? (Ans: Skew centroids; preprocess.)</li>
            </ul>
        </div>
    </section>

    <section id="hc">
        <h2>15. Hierarchical Clustering</h2>
        <p><strong>Explanation:</strong> Builds dendrogram by merging/splitting clusters; agglomerative/divisive.</p>
        <h3>When/Where to Use:</h3>
        <p>Unknown k, visualize hierarchy; e.g., taxonomy.</p>
        <h3>Mathematical Formulas:</h3>
        <div class="formula">
            <p>Linkage: Single \( d(C_i,C_j) = \min d(x,y) \), Complete max, Average mean.</p>
        </div>
        <h3>Diagram:</h3>
        <svg width="300" height="200">
            <line x1="150" y1="20" x2="150" y2="180" stroke="#2c3e50"/>
            <line x1="100" y1="100" x2="50" y2="150" stroke="#2c3e50"/>
            <line x1="200" y1="100" x2="250" y2="150" stroke="#2c3e50"/>
            <text x="140" y="10">Dendrogram</text>
        </svg>
        <h3>Chart: Linkage Comparison</h3>
        <canvas id="chart-hc"></canvas>
        <script>
            const ctx15 = document.getElementById('chart-hc').getContext('2d');
            new Chart(ctx15, { type: 'line', data: { labels: [1,2,3], datasets: [{ label: 'Dist', data: [2,4,6], borderColor: '#1abc9c' }] } });
        </script>
        <h3>Important Interview Questions:</h3>
        <div class="interview">
            <ul>
                <li>Q: Agglomerative vs Divisive? (Ans: Bottom-up merge vs top-down split.)</li>
                <li>Q: Cut height for k? (Ans: Where dendrogram branches.)</li>
                <li>Q: Computational complexity? (Ans: O(n^2) or O(n^3).)</li>
                <li>Q: Distance metrics? (Ans: Euclidean, Manhattan, cosine.)</li>
                <li>Q: Vs K-means? (Ans: No k needed upfront; hierarchical.)</li>
            </ul>
        </div>
    </section>

    <section id="apriori">
        <h2>16. Apriori Algorithm</h2>
        <p><strong>Explanation:</strong> Association rule mining; finds frequent itemsets using support, then generates rules.</p>
        <h3>When/Where to Use:</h3>
        <p>Market basket analysis; e.g., retail recommendations.</p>
        <h3>Mathematical Formulas:</h3>
        <div class="formula">
            <p>Support: \( \frac{\sigma(X \cup Y)}{N} \)</p>
            <p>Confidence: \( \frac{\sigma(X \cup Y)}{\sigma(X)} \)</p>
            <p>Lift: \( \frac{\conf(X \to Y)}{\sup(Y)} \)</p>
        </div>
        <h3>Diagram:</h3>
        <svg width="300" height="150">
            <rect x="50" y="50" width="60" height="40" fill="#e74c3c"><text x="60" y="75">Itemset</text></rect>
            <rect x="190" y="50" width="60" height="40" fill="#2ecc71"><text x="200" y="75">Rule</text></rect>
            <line x1="110" y1="70" x2="190" y2="70" stroke="#3498db"/>
        </svg>
        <h3>Chart: Support Levels</h3>
        <canvas id="chart-apriori"></canvas>
        <script>
            const ctx16 = document.getElementById('chart-apriori').getContext('2d');
            new Chart(ctx16, { type: 'bar', data: { labels: ['Item1', 'Item2'], datasets: [{ label: 'Supp', data: [0.3, 0.2], backgroundColor: '#e67e22' }] } });
        </script>
        <h3>Important Interview Questions:</h3>
        <div class="interview">
            <ul>
                <li>Q: Apriori property? (Ans: Monotonic: subsets of frequent are frequent.)</li>
                <li>Q: Min support/conf? (Ans: Thresholds for pruning.)</li>
                <li>Q: Candidate generation? (Ans: Join-prune steps.)</li>
                <li>Q: Vs FP-Growth? (Ans: Apriori candidate-based; FP tree-based, faster.)</li>
                <li>Q: Real-world app? (Ans: Amazon recommendations.)</li>
            </ul>
        </div>
    </section>

    <section id="ucb">
        <h2>17. Upper Confidence Bound (UCB)</h2>
        <p><strong>Explanation:</strong> Reinforcement learning for multi-armed bandit; balances exploration (UCB) and exploitation (mean reward).</p>
        <h3>When/Where to Use:</h3>
        <p>Online ad selection, A/B testing.</p>
        <h3>Mathematical Formulas:</h3>
        <div class="formula">
            <p>UCB: \( \bar{x}_j + \sqrt{\frac{2 \ln n}{n_j}} \)</p>
            <p>Select arm with max UCB.</p>
        </div>
        <h3>Diagram:</h3>
        <svg width="300" height="150">
            <rect x="50" y="50" width="50" height="50" fill="#3498db"/>
            <rect x="200" y="50" width="50" height="50" fill="#e74c3c"/>
            <text x="120" y="130">Arms with Bounds</text>
        </svg>
        <h3>Chart: Cumulative Reward</h3>
        <canvas id="chart-ucb"></canvas>
        <script>
            const ctx17 = document.getElementById('chart-ucb').getContext('2d');
            new Chart(ctx17, { type: 'line', data: { labels: [1,10,20], datasets: [{ label: 'UCB', data: [5,45,90], borderColor: '#27ae60' }] } });
        </script>
        <h3>Important Interview Questions:</h3>
        <div class="interview">
            <ul>
                <li>Q: Exploration vs Exploitation? (Ans: UCB adds optimism to uncertain arms.)</li>
                <li>Q: Vs epsilon-greedy? (Ans: UCB non-uniform exploration.)</li>
                <li>Q: Regret bound? (Ans: Logarithmic in time.)</li>
                <li>Q: When fails? (Ans: Non-stationary rewards.)</li>
                <li>Q: Implementation? (Ans: Track plays and rewards per arm.)</li>
            </ul>
        </div>
    </section>

    <section id="ts">
        <h2>18. Thompson Sampling</h2>
        <p><strong>Explanation:</strong> Bayesian bandit; samples from posterior reward distribution for action selection.</p>
        <h3>When/Where to Use:</h3>
        <p>Uncertain environments; e.g., personalized recommendations.</p>
        <h3>Mathematical Formulas:</h3>
        <div class="formula">
            <p>Sample θ ~ Posterior (Beta for Bernoulli)</p>
            <p>Select argmax E[reward|θ]</p>
        </div>
        <h3>Diagram:</h3>
        <svg width="300" height="150">
            <path d="M50 100 Q100 50 150 100 Q200 150 250 100" stroke="#3498db" fill="none"/>
            <text x="120" y="130">Posterior Samples</text>
        </svg>
        <h3>Chart: Sampling Distribution</h3>
        <canvas id="chart-ts"></canvas>
        <script>
            const ctx18 = document.getElementById('chart-ts').getContext('2d');
            new Chart(ctx18, { type: 'scatter', data: { datasets: [{ label: 'Samples', data: [{x:0.2,y:0.8},{x:0.5,y:0.6}], backgroundColor: '#9b59b6' }] } });
        </script>
        <h3>Important Interview Questions:</h3>
        <div class="interview">
            <ul>
                <li>Q: Bayesian update? (Ans: Prior + likelihood → posterior.)</li>
                <li>Q: Vs UCB? (Ans: TS probabilistic; better in some cases.)</li>
                <li>Q: Beta prior for binary? (Ans: Yes, conjugate.)</li>
                <li>Q: Computational cost? (Ans: Sampling overhead.)</li>
                <li>Q: Regret? (Ans: Asymptotically optimal.)</li>
            </ul>
        </div>
    </section>

    <section id="nlp">
        <h2>19. Natural Language Processing (Bag of Words, TF-IDF)</h2>
        <p><strong>Explanation:</strong> BoW ignores order, counts words; TF-IDF weights by rarity.</p>
        <h3>When/Where to Use:</h3>
        <p>Text classification; e.g., spam filtering.</p>
        <h3>Mathematical Formulas:</h3>
        <div class="formula">
            <p>TF: \( \frac{f_{t,d}}{|d|} \), IDF: \( \log \frac{N}{df_t} \)</p>
            <p>TF-IDF: TF * IDF</p>
        </div>
        <h3>Diagram:</h3>
        <svg width="300" height="100">
            <rect x="50" y="20" width="40" height="20" fill="#e74c3c"><text x="55" y="35">Word1:2</text></rect>
            <rect x="100" y="20" width="40" height="20" fill="#3498db"><text x="105" y="35">Word2:1</text></rect>
            <text x="120" y="60">Bag Vector</text>
        </svg>
        <h3>Chart: Word Frequencies</h3>
        <canvas id="chart-nlp"></canvas>
        <script>
            const ctx19 = document.getElementById('chart-nlp').getContext('2d');
            new Chart(ctx19, { type: 'bar', data: { labels: ['WordA', 'WordB'], datasets: [{ label: 'TF-IDF', data: [0.8, 0.3], backgroundColor: '#34495e' }] } });
        </script>
        <h3>Important Interview Questions:</h3>
        <div class="interview">
            <ul>
                <li>Q: BoW limitations? (Ans: No semantics, order ignored.)</li>
                <li>Q: TF-IDF vs BoW? (Ans: TF-IDF downweights common words.)</li>
                <li>Q: Stemming vs Lemmatization? (Ans: Stem rough; Lemma context-aware.)</li>
                <li>Q: Embeddings better? (Ans: Yes, Word2Vec captures meaning.)</li>
                <li>Q: Sparse matrix? (Ans: Use CountVectorizer sparse output.)</li>
            </ul>
        </div>
    </section>

    <section id="ann">
        <h2>20. Artificial Neural Networks (ANN)</h2>
        <p><strong>Explanation:</strong> Layers of neurons with weights, biases; backprop for training.</p>
        <h3>When/Where to Use:</h3>
        <p>Complex patterns; e.g., tabular deep learning.</p>
        <h3>Mathematical Formulas:</h3>
        <div class="formula">
            <p>Neuron: \( z = \sigma (W x + b) \)</p>
            <p>Loss: Cross-entropy, GD: \( \theta = \theta - \eta \frac{\partial L}{\partial \theta} \)</p>
        </div>
        <h3>Diagram:</h3>
        <svg width="300" height="200">
            <circle cx="50" cy="100" r="20" fill="#3498db"/>
            <circle cx="150" cy="60" r="20" fill="#e74c3c"/>
            <circle cx="150" cy="140" r="20" fill="#e74c3c"/>
            <circle cx="250" cy="100" r="20" fill="#2ecc71"/>
            <line x1="70" y1="100" x2="130" y2="60" stroke="#000"/>
            <line x1="70" y1="100" x2="130" y2="140" stroke="#000"/>
            <text x="120" y="30">Hidden Layer</text>
        </svg>
        <h3>Chart: Loss Curve</h3>
        <canvas id="chart-ann"></canvas>
        <script>
            const ctx20 = document.getElementById('chart-ann').getContext('2d');
            new Chart(ctx20, { type: 'line', data: { labels: [1,2,3,4], datasets: [{ label: 'Loss', data: [2,1.5,1,0.5], borderColor: '#f39c12' }] } });
        </script>
        <h3>Important Interview Questions:</h3>
        <div class="interview">
            <ul>
                <li>Q: Activation functions? (Ans: ReLU fast, Sigmoid for output.)</li>
                <li>Q: Vanishing gradient? (Ans: Sigmoid; use ReLU/Xavier init.)</li>
                <li>Q: Dropout? (Ans: Random neuron drop to prevent overfit.)</li>
                <li>Q: Batch norm? (Ans: Normalize inputs per layer.)</li>
                <li>Q: Optimizers? (Ans: Adam adaptive LR.)</li>
            </ul>
        </div>
    </section>

    <section id="cnn">
        <h2>21. Convolutional Neural Networks (CNN)</h2>
        <p><strong>Explanation:</strong> For images; convolutions extract features, pooling reduces dims, FC for classification.</p>
        <h3>When/Where to Use:</h3>
        <p>Computer vision; e.g., object detection.</p>
        <h3>Mathematical Formulas:</h3>
        <div class="formula">
            <p>Conv: \( (f * g)(i,j) = \sum \sum f(m,n) g(i-m, j-n) \)</p>
            <p>Pooling: Max/Avg over window.</p>
        </div>
        <h3>Diagram:</h3>
        <svg width="300" height="200">
            <rect x="50" y="50" width="100" height="100" fill="#ddd"/>
            <text x="100" y="100">Input Image</text>
            <rect x="180" y="80" width="60" height="60" fill="#3498db"/>
            <text x="190" y="110">Feature Map</text>
        </svg>
        <h3>Chart: Layer Outputs</h3>
        <canvas id="chart-cnn"></canvas>
        <script>
            const ctx21 = document.getElementById('chart-cnn').getContext('2d');
            new Chart(ctx21, { type: 'bar', data: { labels: ['Conv1', 'Pool', 'FC'], datasets: [{ label: 'Filters', data: [32,16,10], backgroundColor: '#e67e22' }] } });
        </script>
        <h3>Important Interview Questions:</h3>
        <div class="interview">
            <ul>
                <li>Q: Stride/padding? (Ans: Stride downsample; padding preserve size.)</li>
                <li>Q: Transfer learning? (Ans: Fine-tune pre-trained like VGG.)</li>
                <li>Q: Why conv over FC? (Ans: Parameter sharing, translation invariance.)</li>
                <li>Q: Data aug? (Ans: Rotate/flip to increase data.)</li>
                <li>Q: Architectures? (Ans: AlexNet, ResNet with skip connections.)</li>
            </ul>
        </div>
    </section>

    <section id="pca">
        <h2>22. Principal Component Analysis (PCA)</h2>
        <p><strong>Explanation:</strong> Dimensionality reduction; projects to orthogonal components maximizing variance.</p>
        <h3>When/Where to Use:</h3>
        <p>High-dim data viz/reduce compute; e.g., genomics.</p>
        <h3>Mathematical Formulas:</h3>
        <div class="formula">
            <p>PCs: Eigenvectors of cov matrix, sorted by eigenvalues (variance).</p>
            <p>Projection: \( Z = X V_k \)</p>
        </div>
        <h3>Diagram:</h3>
        <svg width="300" height="200">
            <line x1="50" y1="150" x2="250" y2="50" stroke="#3498db"/>
            <line x1="50" y1="50" x2="250" y2="150" stroke="#e74c3c"/>
            <text x="120" y="180">PC1, PC2</text>
        </svg>
        <h3>Chart: Explained Variance</h3>
        <canvas id="chart-pca"></canvas>
        <script>
            const ctx22 = document.getElementById('chart-pca').getContext('2d');
            new Chart(ctx22, { type: 'bar', data: { labels: ['PC1', 'PC2'], datasets: [{ label: 'Var', data: [0.6, 0.3], backgroundColor: '#27ae60' }] } });
        </script>
        <h3>Important Interview Questions:</h3>
        <div class="interview">
            <ul>
                <li>Q: Supervised vs unsupervised? (Ans: Unsupervised; LDA supervised.)</li>
                <li>Q: 95% variance? (Ans: Choose k where cum var >=0.95.)</li>
                <li>Q: Mean center data? (Ans: Yes, for cov matrix.)</li>
                <li>Q: Curse mitigation? (Ans: Reduces noise/dims.)</li>
                <li>Q: SVD relation? (Ans: PCA via SVD of centered X.)</li>
            </ul>
        </div>
    </section>

    <section id="lda">
        <h2>23. Linear Discriminant Analysis (LDA)</h2>
        <p><strong>Explanation:</strong> Supervised reduction; maximizes class separability.</p>
        <h3>When/Where to Use:</h3>
        <p>Classification preprocessing; e.g., face recognition.</p>
        <h3>Mathematical Formulas:</h3>
        <div class="formula">
            <p>Maximize \( \frac{|\Sigma_b|}{|\Sigma_w|} \), where Σb between-class, Σw within.</p>
        </div>
        <h3>Diagram:</h3>
        <svg width="300" height="200">
            <circle cx="100" cy="80" r="20" fill="#e74c3c"/>
            <circle cx="200" cy="120" r="20" fill="#3498db"/>
            <line x1="50" y1="100" x2="250" y2="100" stroke="#2ecc71"/>
            <text x="120" y="180">Class Separation</text>
        </svg>
        <h3>Chart: LDA Projections</h3>
        <canvas id="chart-lda"></canvas>
        <script>
            const ctx23 = document.getElementById('chart-lda').getContext('2d');
            new Chart(ctx23, { type: 'scatter', data: { datasets: [{ label: 'Proj', data: [{x:1,y:2},{x:3,y:4}], backgroundColor: '#1abc9c' }] } });
        </script>
        <h3>Important Interview Questions:</h3>
        <div class="interview">
            <ul>
                <li>Q: PCA vs LDA? (Ans: PCA variance; LDA discrimination.)</li>
                <li>Q: Max components? (Ans: min(n_classes-1, n_features).)</li>
                <li>Q: Assumptions? (Ans: Gaussian classes, equal cov.)</li>
                <li>Q: As classifier? (Ans: Yes, QDA quadratic.)</li>
                <li>Q: High dims? (Ans: Reduces to discriminant space.)</li>
            </ul>
        </div>
    </section>

    <section id="kpca">
        <h2>24. Kernel PCA</h2>
        <p><strong>Explanation:</strong> Non-linear PCA via kernel trick; maps to higher dim then projects.</p>
        <h3>When/Where to Use:</h3>
        <p>Non-linear manifolds; e.g., Swiss roll data.</p>
        <h3>Mathematical Formulas:</h3>
        <div class="formula">
            <p>Kernel Matrix K = Φ(X)^T Φ(X)</p>
            <p>Eigen decomp on K for PCs.</p>
        </div>
        <h3>Diagram:</h3>
        <svg width="300" height="200">
            <path d="M50 150 Q100 50 150 150 Q200 100 250 150" stroke="#3498db" fill="none"/>
            <text x="120" y="180">Non-Linear Projection</text>
        </svg>
        <h3>Chart: Kernel Variance</h3>
        <canvas id="chart-kpca"></canvas>
        <script>
            const ctx24 = document.getElementById('chart-kpca').getContext('2d');
            new Chart(ctx24, { type: 'line', data: { labels: ['RBF', 'Poly'], datasets: [{ label: 'Var', data: [0.7, 0.5], borderColor: '#9b59b6' }] } });
        </script>
        <h3>Important Interview Questions:</h3>
        <div class="interview">
            <ul>
                <li>Q: Kernel choice? (Ans: RBF for complex; poly for polynomial.)</li>
                <li>Q: Vs standard PCA? (Ans: Handles non-linear.)</li>
                <li>Q: Compute cost? (Ans: O(n^3) for kernel matrix.)</li>
                <li>Q: Inverse transform? (Ans: Approximate via pre-image.)</li>
                <li>Q: Overfitting? (Ans: Tune gamma.)</li>
            </ul>
        </div>
    </section>

    <section id="modelsel">
        <h2>25. Model Selection & Boosting (K-Fold CV, Grid Search)</h2>
        <p><strong>Explanation:</strong> CV splits data k times for robust eval; Grid searches hyperparams exhaustively. Boosting (e.g., XGBoost) sequential trees focusing on errors.</p>
        <h3>When/Where to Use:</h3>
        <p>Tuning models; e.g., hyperparam optimization in production.</p>
        <h3>Mathematical Formulas:</h3>
        <div class="formula">
            <p>K-Fold: Avg score over k folds.</p>
            <p>Grid: All combos of param grid.</p>
            <p>Boost: \( F_m = F_{m-1} + \nu h_m \), ν learning rate.</p>
        </div>
        <h3>Diagram:</h3>
        <svg width="300" height="150">
            <rect x="50" y="20" width="40" height="40" fill="#e74c3c"/>
            <rect x="110" y="20" width="40" height="40" fill="#3498db"/>
            <rect x="170" y="20" width="40" height="40" fill="#2ecc71"/>
            <text x="120" y="80">K Folds</text>
        </svg>
        <h3>Chart: CV Scores</h3>
        <canvas id="chart-modelsel"></canvas>
        <script>
            const ctx25 = document.getElementById('chart-modelsel').getContext('2d');
            new Chart(ctx25, { type: 'boxplot', data: { labels: ['Fold1-5'], datasets: [{ label: 'Score', data: [[0.8,0.85,0.82,0.88,0.9]] }] } }); // Note: Chart.js needs plugin for boxplot, simplified as bar
            new Chart(ctx25, { type: 'bar', data: { labels: ['Avg'], datasets: [{ label: 'CV', data: [0.85], backgroundColor: '#f39c12' }] } });
        </script>
        <h3>Important Interview Questions:</h3>
        <div class="interview">
            <ul>
                <li>Q: K-Fold vs Train-Test? (Ans: CV more reliable for small data.)</li>
                <li>Q: Stratified K-Fold? (Ans: Preserves class ratios.)</li>
                <li>Q: Grid vs Random Search? (Ans: Grid exhaustive; Random faster for large space.)</li>
                <li>Q: Boosting stages? (Ans: Sequential, weight hard examples.)</li>
                <li>Q: XGBoost advantages? (Ans: Handles missing, reg, parallel.)</li>
            </ul>
        </div>
    </section>

</body>
</html>
